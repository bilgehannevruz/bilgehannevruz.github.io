{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li> <p><code>mkdocs -h</code> - Print help message and exit.</p> </li> <li> <p>Testing ci</p> </li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"hpc-engineer/ansible/","title":"Ansible","text":""},{"location":"hpc-engineer/ansible/#overview","title":"Overview","text":"<p>This section covers Ansible, a powerful automation tool.</p>"},{"location":"hpc-engineer/ansible/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>Playbooks</li> <li>Roles</li> </ul>"},{"location":"hpc-engineer/ansible/#docker-setup","title":"Docker Setup","text":"<p>To test Ansible scripts, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/ansible/#docker-compose-setup","title":"Docker Compose Setup","text":"<p>We use Docker Compose to set up an Ansible controller and multiple nodes for testing.</p>"},{"location":"hpc-engineer/ansible/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t ansible .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm ansible\n</code></pre></p> </li> <li> <p>Use Docker Compose to set up the environment:     <pre><code>docker-compose up -d\n</code></pre></p> </li> <li> <p>Access the Ansible controller:     <pre><code>docker exec -it ansible-controller /bin/bash\n</code></pre></p> </li> <li> <p>Verify the setup by running an Ansible command:     <pre><code>ansible all -m ping -i inventory\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/ansible/#additional-resources","title":"Additional Resources","text":"<ul> <li>Ansible Documentation</li> <li>Ansible GitHub Repository</li> </ul>"},{"location":"hpc-engineer/ansible/introduction/","title":"Introduction to Ansible","text":""},{"location":"hpc-engineer/ansible/introduction/#overview","title":"Overview","text":"<p>Ansible is an open-source automation tool used for configuration management, application deployment, and task automation. It uses a simple, human-readable language called YAML to describe automation jobs.</p>"},{"location":"hpc-engineer/ansible/introduction/#key-features","title":"Key Features","text":"<ul> <li>Agentless: No need to install any software on the nodes.</li> <li>Idempotent: Ensures that the system reaches the desired state without unintended changes.</li> <li>Extensible: Supports custom modules and plugins.</li> </ul>"},{"location":"hpc-engineer/ansible/introduction/#example-playbook","title":"Example Playbook","text":"<p>Here is a simple example of an Ansible playbook that installs Nginx on a remote server.</p> <pre><code>- name: Install Nginx\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Ensure Nginx is installed\n      apt:\n        name: nginx\n        state: present\n</code></pre>"},{"location":"hpc-engineer/ansible/introduction/#how-to-run","title":"How to Run","text":"<ol> <li> <p>Create an inventory file hosts with the following content:     <pre><code>[webservers]\nyour_server_ip\n</code></pre></p> </li> <li> <p>Run the playbook     <pre><code>ansible-playbook -i hosts install_nginx.yml\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/ansible/playbooks/","title":"Ansible Playbooks","text":""},{"location":"hpc-engineer/ansible/playbooks/#overview","title":"Overview","text":"<p>Ansible playbooks are YAML files that define a series of tasks to be executed on remote hosts. Playbooks are the core of Ansible's configuration, deployment, and orchestration capabilities.</p>"},{"location":"hpc-engineer/ansible/playbooks/#structure-of-a-playbook","title":"Structure of a Playbook","text":"<p>A playbook consists of one or more plays. Each play targets a group of hosts and defines tasks to be executed on those hosts.</p>"},{"location":"hpc-engineer/ansible/playbooks/#example-playbook","title":"Example Playbook","text":"<p>Here is an example of a playbook that updates all packages on a group of servers.</p> <pre><code>- name: Update all packages\n  hosts: all\n  become: yes\n  tasks:\n    - name: Update apt cache\n      apt:\n        update_cache: yes\n\n    - name: Upgrade all packages\n      apt:\n        upgrade: dist\n</code></pre>"},{"location":"hpc-engineer/ansible/playbooks/#explanation","title":"Explanation","text":"<ul> <li><code>name</code>: A description of the play.</li> <li><code>hosts</code>: The group of hosts to target.</li> <li><code>become</code>: Whether to use privilege escalation (e.g., sudo).</li> <li><code>tasks</code>: A list of tasks to execute.</li> </ul>"},{"location":"hpc-engineer/ansible/playbooks/#running-a-playbook","title":"Running a Playbook","text":"<p>To run a playbook, use the ansible-playbook command: <pre><code>ansible-playbook -i inventory_file playbook.yml\n</code></pre></p>"},{"location":"hpc-engineer/ansible/playbooks/#additional-resources","title":"Additional Resources","text":"<ul> <li>Ansible Playbooks Documentation</li> </ul>"},{"location":"hpc-engineer/ansible/roles/","title":"Ansible Roles","text":""},{"location":"hpc-engineer/ansible/roles/#overview","title":"Overview","text":"<p>Ansible roles allow you to group related tasks, handlers, variables, and other Ansible components into reusable units. Roles help in organizing playbooks and making them more maintainable.</p>"},{"location":"hpc-engineer/ansible/roles/#structure-of-a-role","title":"Structure of a Role","text":"<p>A role has a specific directory structure. Here is an example:</p>"},{"location":"hpc-engineer/ansible/roles/#example-role","title":"Example Role","text":"<p>Here is an example of a simple role that installs and starts Nginx.</p>"},{"location":"hpc-engineer/ansible/roles/#rolesnginxtasksmainyml","title":"<code>roles/nginx/tasks/main.yml</code>","text":"<pre><code>- name: Ensure Nginx is installed\n  apt:\n    name: nginx\n    state: present\n\n- name: Ensure Nginx is started\n  service:\n    name: nginx\n    state: started\n    enabled: yes\n</code></pre>"},{"location":"hpc-engineer/ansible/roles/#using-roles-in-a-playbook","title":"Using Roles in a Playbook","text":"<p>To use a role in a playbook, you can include it in the roles section.</p>"},{"location":"hpc-engineer/ansible/roles/#example-playbook","title":"Example Playbook:","text":"<pre><code>- name: Apply common configuration\n  hosts: all\n  roles:\n    - common\n\n- name: Apply Nginx role\n  hosts: webservers\n  roles:\n    - nginx\n</code></pre>"},{"location":"hpc-engineer/ansible/roles/#explanation","title":"Explanation","text":"<ul> <li><code>roles</code>: A list of roles to apply to the hosts.</li> </ul>"},{"location":"hpc-engineer/ansible/roles/#running-a-playbook","title":"Running a Playbook","text":"<p>To run a playbook, use the ansible-playbook command: <pre><code>ansible-playbook -i inventory_file playbook_with_roles.yml\n</code></pre></p>"},{"location":"hpc-engineer/cloud_computing/","title":"Cloud Computing","text":""},{"location":"hpc-engineer/cloud_computing/#overview","title":"Overview","text":"<p>This section covers various aspects of cloud computing.</p>"},{"location":"hpc-engineer/cloud_computing/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>AWS</li> <li>Azure</li> </ul>"},{"location":"hpc-engineer/cloud_computing/#docker-setup","title":"Docker Setup","text":"<p>To test cloud computing tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/cloud_computing/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/cloud_computing/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t cloud_computing .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm cloud_computing\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/cloud_computing/#additional-resources","title":"Additional Resources","text":"<ul> <li>AWS Documentation</li> <li>Azure Documentation</li> <li>Google Cloud Documentation</li> </ul>"},{"location":"hpc-engineer/cloud_computing/aws/","title":"AWS (Amazon Web Services)","text":""},{"location":"hpc-engineer/cloud_computing/aws/#overview","title":"Overview","text":"<p>Amazon Web Services (AWS) is a comprehensive and widely adopted cloud platform, offering over 200 fully featured services from data centers globally. AWS provides a variety of services including computing power, storage options, and networking capabilities.</p>"},{"location":"hpc-engineer/cloud_computing/aws/#key-services","title":"Key Services","text":"<ul> <li>EC2 (Elastic Compute Cloud): Provides scalable computing capacity in the cloud.</li> <li>S3 (Simple Storage Service): Object storage service that offers industry-leading scalability, data availability, security, and performance.</li> <li>RDS (Relational Database Service): Makes it easy to set up, operate, and scale a relational database in the cloud.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/aws/#example-launching-an-ec2-instance","title":"Example: Launching an EC2 Instance","text":"<p>Here is an example of how to launch an EC2 instance using the AWS CLI.</p>"},{"location":"hpc-engineer/cloud_computing/aws/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CLI installed and configured with your credentials.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/aws/#commands","title":"Commands","text":"<ol> <li> <p>Create a key pair:     <pre><code>aws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text &gt; MyKeyPair.pem\n</code></pre></p> </li> <li> <p>Launch an EC2 instance:     <pre><code>aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-0123456789abcdef0 --subnet-id subnet-0123456789abcdef0\n</code></pre></p> </li> <li> <p>Describe the instance to get its public IP:     <pre><code>aws ec2 describe-instances --instance-ids i-0123456789abcdef0 --query 'Reservations[*].Instances[*].PublicIpAddress' --output text\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/cloud_computing/aws/#additional-resources","title":"Additional Resources","text":"<ul> <li>AWS EC2 Documentation</li> <li>AWS S3 Documentation</li> <li>AWS RDS Documentation</li> </ul>"},{"location":"hpc-engineer/cloud_computing/azure/","title":"Azure (Microsoft Azure)","text":""},{"location":"hpc-engineer/cloud_computing/azure/#overview","title":"Overview","text":"<p>Microsoft Azure is a cloud computing service created by Microsoft for building, testing, deploying, and managing applications and services through Microsoft-managed data centers. It provides a range of cloud services, including those for compute, analytics, storage, and networking.</p>"},{"location":"hpc-engineer/cloud_computing/azure/#key-services","title":"Key Services","text":"<ul> <li>Azure Virtual Machines: Provides on-demand, scalable computing resources.</li> <li>Azure Blob Storage: Massively scalable object storage for unstructured data.</li> <li>Azure SQL Database: Fully managed relational database with built-in intelligence.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/azure/#example-creating-a-virtual-machine","title":"Example: Creating a Virtual Machine","text":"<p>Here is an example of how to create a virtual machine using the Azure CLI.</p>"},{"location":"hpc-engineer/cloud_computing/azure/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure CLI installed and configured with your credentials.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/azure/#commands","title":"Commands","text":"<ol> <li> <p>Create a resource group:     <pre><code>az group create --name MyResourceGroup --location eastus\n</code></pre></p> </li> <li> <p>Create a virtual machine:     <pre><code>az vm create \\\n  --resource-group MyResourceGroup \\\n  --name MyVM \\\n  --image UbuntuLTS \\\n  --admin-username azureuser \\\n  --generate-ssh-keys\n</code></pre></p> </li> <li> <p>Get the public IP address of the virtual machine:     <pre><code>az vm list-ip-addresses --resource-group MyResourceGroup --name MyVM --output table\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/cloud_computing/azure/#additional-resources","title":"Additional Resources","text":"<ul> <li>Azure Virtual Machines Documentation</li> <li>Azure Blob Storage Documentation</li> <li>Azure SQL Database Documentation</li> </ul>"},{"location":"hpc-engineer/cloud_computing/introduction/","title":"Introduction to Cloud Computing","text":""},{"location":"hpc-engineer/cloud_computing/introduction/#overview","title":"Overview","text":"<p>Cloud computing provides on-demand delivery of computing resources over the internet. It allows users to access and use IT resources without owning and managing physical hardware.</p>"},{"location":"hpc-engineer/cloud_computing/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>Infrastructure as a Service (IaaS): Provides virtualized computing resources over the internet.</li> <li>Platform as a Service (PaaS): Provides a platform allowing customers to develop, run, and manage applications.</li> <li>Software as a Service (SaaS): Delivers software applications over the internet.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/introduction/#benefits","title":"Benefits","text":"<ul> <li>Scalability: Easily scale resources up or down based on demand.</li> <li>Cost Efficiency: Pay only for the resources you use.</li> <li>Flexibility: Access resources from anywhere with an internet connection.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/introduction/#example-deploying-a-virtual-machine-on-aws","title":"Example: Deploying a Virtual Machine on AWS","text":"<p>Here is an example of how to deploy a virtual machine on AWS using the AWS CLI.</p>"},{"location":"hpc-engineer/cloud_computing/introduction/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CLI installed and configured with your credentials.</li> </ul>"},{"location":"hpc-engineer/cloud_computing/introduction/#commands","title":"Commands","text":"<ol> <li> <p>Create a key pair:     <pre><code>aws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text &gt; MyKeyPair.pem\n</code></pre></p> </li> <li> <p>Launch an EC2 instance:     <pre><code>aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-0123456789abcdef0 --subnet-id subnet-0123456789abcdef0\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/cloud_computing/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>AWS Documentation</li> <li>Azure Documentation</li> <li>Google Cloud Documentation</li> </ul>"},{"location":"hpc-engineer/computer_architecture/","title":"Computer Architecture","text":""},{"location":"hpc-engineer/computer_architecture/#overview","title":"Overview","text":"<p>This section covers the fundamentals of computer architecture.</p>"},{"location":"hpc-engineer/computer_architecture/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>CPU Design</li> <li>Memory Hierarchy</li> </ul>"},{"location":"hpc-engineer/computer_architecture/#docker-setup","title":"Docker Setup","text":"<p>To test computer architecture simulations, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/computer_architecture/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/computer_architecture/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t computer_architecture .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm computer_architecture\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/computer_architecture/#additional-resources","title":"Additional Resources","text":"<ul> <li>Computer Architecture: A Quantitative Approach</li> <li>Introduction to Computer Architecture</li> </ul>"},{"location":"hpc-engineer/computer_architecture/cpu_design/","title":"CPU Design","text":""},{"location":"hpc-engineer/computer_architecture/cpu_design/#overview","title":"Overview","text":"<p>CPU design involves creating the architecture and microarchitecture of a central processing unit. It includes defining the instruction set, designing the control unit, and optimizing the data path.</p>"},{"location":"hpc-engineer/computer_architecture/cpu_design/#key-components","title":"Key Components","text":"<ul> <li>Instruction Set Architecture (ISA): Defines the set of instructions that the CPU can execute.</li> <li>Control Unit: Manages the execution of instructions by directing the operation of the other components.</li> <li>Data Path: The hardware that performs the actual data processing operations.</li> </ul>"},{"location":"hpc-engineer/computer_architecture/cpu_design/#example-simple-cpu-design","title":"Example: Simple CPU Design","text":"<p>Here is an example of a simple CPU design using a hypothetical assembly language.</p>"},{"location":"hpc-engineer/computer_architecture/cpu_design/#assembly-code","title":"Assembly Code","text":"<pre><code>LOAD R1, 1000  ; Load the value at memory address 1000 into register R1\nADD R1, R2     ; Add the value in register R2 to the value in register R1\nSTORE R1, 1001 ; Store the result from register R1 into memory address 1001\n</code></pre>"},{"location":"hpc-engineer/computer_architecture/cpu_design/#explanation","title":"Explanation","text":"<p><code>LOAD</code>: Loads a value from memory into a register. <code>ADD</code>: Adds the values of two registers. <code>STORE</code>: Stores a value from a register into memory.</p>"},{"location":"hpc-engineer/computer_architecture/cpu_design/#additional-resources","title":"Additional Resources","text":"<ul> <li>Computer Architecture: A Quantitative Approach</li> <li>Introduction to Computer Architecture</li> </ul>"},{"location":"hpc-engineer/computer_architecture/introduction/","title":"Introduction to Computer Architecture","text":""},{"location":"hpc-engineer/computer_architecture/introduction/#overview","title":"Overview","text":"<p>Computer architecture refers to the design and organization of a computer's core components, including the CPU, memory, and input/output systems. It defines the system's functionality, performance, and scalability.</p>"},{"location":"hpc-engineer/computer_architecture/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>CPU (Central Processing Unit): The brain of the computer that performs instructions defined by software.</li> <li>Memory Hierarchy: The organization of different types of memory (e.g., cache, RAM, disk) to optimize performance.</li> <li>I/O Systems: Interfaces and devices that allow the computer to communicate with the external environment.</li> </ul>"},{"location":"hpc-engineer/computer_architecture/introduction/#example-basic-cpu-design","title":"Example: Basic CPU Design","text":"<p>Here is an example of a simple CPU design using a hypothetical assembly language.</p>"},{"location":"hpc-engineer/computer_architecture/introduction/#assembly-code","title":"Assembly Code","text":"<pre><code>LOAD R1, 1000  ; Load the value at memory address 1000 into register R1\nADD R1, R2     ; Add the value in register R2 to the value in register R1\nSTORE R1, 1001 ; Store the result from register R1 into memory address 1001\n</code></pre>"},{"location":"hpc-engineer/computer_architecture/introduction/#explanation","title":"Explanation","text":"<p><code>LOAD</code>: Loads a value from memory into a register. <code>ADD</code>: Adds the values of two registers. <code>STORE</code>: Stores a value from a register into memory.</p>"},{"location":"hpc-engineer/computer_architecture/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>Computer Architecture: A Quantitative Approach</li> <li>Introduction to Computer Architecture</li> </ul>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/","title":"Memory Hierarchy","text":""},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#overview","title":"Overview","text":"<p>Memory hierarchy is a structure that uses multiple levels of memory with different speeds and sizes to optimize performance and cost. The goal is to provide a balance between fast access times and large storage capacity.</p>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#key-components","title":"Key Components","text":"<ul> <li>Registers: The fastest and smallest type of memory located within the CPU.</li> <li>Cache: A small, fast memory located close to the CPU to store frequently accessed data.</li> <li>Main Memory (RAM): Larger and slower than cache, used to store data and instructions currently in use.</li> <li>Secondary Storage: Non-volatile storage such as hard drives and SSDs, used for long-term data storage.</li> </ul>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#example-memory-access","title":"Example: Memory Access","text":"<p>Here is an example of how data might be accessed in a memory hierarchy.</p>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#pseudocode","title":"Pseudocode","text":"<pre><code>if data in registers:\n    access data from registers\nelse if data in cache:\n    access data from cache\nelse if data in main memory:\n    load data into cache\n    access data from cache\nelse:\n    load data into main memory\n    load data into cache\n    access data from cache\n</code></pre>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#explanation","title":"Explanation","text":"<ul> <li><code>Registers</code>: Checked first for the fastest access.</li> <li><code>Cache</code>: Checked next if data is not in registers.</li> <li><code>Main Memory</code>: Loaded into cache if data is not in cache.</li> <li><code>Secondary Storage</code>: Loaded into main memory if data is not in main memory.</li> </ul>"},{"location":"hpc-engineer/computer_architecture/memory_hierarchy/#additional-resources","title":"Additional Resources","text":"<ul> <li>Memory Hierarchy in Computer Architecture</li> <li>Computer Architecture: A Quantitative Approach</li> </ul>"},{"location":"hpc-engineer/distributed_systems/","title":"Distributed Systems","text":""},{"location":"hpc-engineer/distributed_systems/#overview","title":"Overview","text":"<p>This section covers the principles of distributed systems.</p>"},{"location":"hpc-engineer/distributed_systems/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>Consistency Models</li> <li>Distributed Algorithms</li> </ul>"},{"location":"hpc-engineer/distributed_systems/#docker-setup","title":"Docker Setup","text":"<p>To test distributed systems tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/distributed_systems/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/distributed_systems/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t distributed_systems .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm distributed_systems\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/distributed_systems/consistency_models/","title":"Consistency Models","text":""},{"location":"hpc-engineer/distributed_systems/consistency_models/#overview","title":"Overview","text":"<p>Consistency models define the rules for how data is viewed and updated across a distributed system. They determine the guarantees provided to the users regarding the visibility and ordering of updates.</p>"},{"location":"hpc-engineer/distributed_systems/consistency_models/#key-consistency-models","title":"Key Consistency Models","text":"<ul> <li>Strong Consistency: Guarantees that all nodes see the same data at the same time after a write operation.</li> <li>Eventual Consistency: Guarantees that, given enough time, all nodes will converge to the same value.</li> <li>Causal Consistency: Guarantees that operations that are causally related are seen by all nodes in the same order.</li> <li>Read-Your-Writes Consistency: Guarantees that a node will always see its own writes.</li> </ul>"},{"location":"hpc-engineer/distributed_systems/consistency_models/#example-eventual-consistency","title":"Example: Eventual Consistency","text":"<p>Here is an example of how eventual consistency works in a distributed system.</p>"},{"location":"hpc-engineer/distributed_systems/consistency_models/#pseudocode","title":"Pseudocode","text":"<pre><code>if write request:\n    write data to local node\n    propagate data to other nodes asynchronously\nelse if read request:\n    read data from local node\n</code></pre>"},{"location":"hpc-engineer/distributed_systems/consistency_models/#explanation","title":"Explanation","text":"<ul> <li><code>Write Request</code>: Data is written to the local node and then propagated to other nodes asynchronously.</li> <li><code>Read Request</code>: Data is read from the local node, which may not have the most recent update.</li> </ul>"},{"location":"hpc-engineer/distributed_systems/consistency_models/#additional-resources","title":"Additional Resources","text":"<ul> <li>Consistency Models in Distributed Systems</li> <li>Distributed Systems: Principles and Paradigms</li> </ul>"},{"location":"hpc-engineer/distributed_systems/introduction/","title":"Introduction to Distributed Systems","text":""},{"location":"hpc-engineer/distributed_systems/introduction/#overview","title":"Overview","text":"<p>Distributed systems consist of multiple independent computers that appear to the users as a single coherent system. These systems work together to achieve a common goal, providing benefits such as scalability, fault tolerance, and resource sharing.</p>"},{"location":"hpc-engineer/distributed_systems/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>Scalability: The ability to handle increased load by adding more resources.</li> <li>Fault Tolerance: The ability to continue operating despite failures.</li> <li>Consistency: Ensuring that all nodes see the same data at the same time.</li> <li>Latency: The time it takes for a message to travel from one node to another.</li> </ul>"},{"location":"hpc-engineer/distributed_systems/introduction/#example-distributed-database","title":"Example: Distributed Database","text":"<p>Here is an example of a distributed database system where data is replicated across multiple nodes.</p>"},{"location":"hpc-engineer/distributed_systems/introduction/#pseudocode","title":"Pseudocode","text":"<pre><code>if write request:\n    write data to primary node\n    replicate data to secondary nodes\nelse if read request:\n    read data from nearest node\n</code></pre>"},{"location":"hpc-engineer/distributed_systems/introduction/#explanation","title":"Explanation","text":"<ul> <li><code>Write Request</code>: Data is written to the local node and then propagated to other nodes asynchronously.</li> <li><code>Read Request</code>: Data is read from the local node, which may not have the most recent update.</li> </ul>"},{"location":"hpc-engineer/distributed_systems/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>Distributed Systems: Principles and Paradigms</li> <li>Introduction to Distributed Systems</li> </ul>"},{"location":"hpc-engineer/gpu_computing/","title":"Index","text":""},{"location":"hpc-engineer/gpu_computing/#overview","title":"Overview","text":"<p>This section covers GPU computing techniques and tools.</p>"},{"location":"hpc-engineer/gpu_computing/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>CUDA</li> <li>OpenCL</li> </ul>"},{"location":"hpc-engineer/gpu_computing/#docker-setup","title":"Docker Setup","text":"<p>To test GPU computing tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/gpu_computing/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/gpu_computing/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t gpu_computing .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run --gpus all -it --rm gpu_computing\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/gpu_computing/#additional-resources","title":"Additional Resources","text":"<ul> <li>NVIDIA CUDA Documentation</li> <li>OpenCL Documentation</li> </ul>"},{"location":"hpc-engineer/gpu_computing/cuda/","title":"Cuda","text":""},{"location":"hpc-engineer/gpu_computing/cuda/#overview","title":"Overview","text":"<p>CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by NVIDIA. It allows developers to use NVIDIA GPUs for general-purpose processing (an approach known as GPGPU, General-Purpose computing on Graphics Processing Units).</p>"},{"location":"hpc-engineer/gpu_computing/cuda/#key-concepts","title":"Key Concepts","text":"<ul> <li>Threads: The smallest unit of execution in CUDA.</li> <li>Blocks: A group of threads that execute the same kernel.</li> <li>Grids: A group of blocks that execute the same kernel.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/cuda/#installation-and-configuration","title":"Installation and Configuration","text":""},{"location":"hpc-engineer/gpu_computing/cuda/#installing-cuda","title":"Installing CUDA","text":"<p>To install CUDA on an HPC environment, follow these steps:</p> <ol> <li> <p>Download the CUDA Toolkit:</p> <ul> <li>Visit the NVIDIA CUDA Toolkit Download Page.</li> <li>Select your operating system, architecture, distribution, and version.</li> <li>Follow the instructions to download the installer.</li> </ul> </li> <li> <p>Install the CUDA Toolkit:</p> <ul> <li>For Ubuntu, you can use the following commands: <pre><code>sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\nsudo sh -c 'echo \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda.list'\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre></li> </ul> </li> <li> <p>Set Up Environment Variables:</p> <ul> <li>Add the following lines to your <code>~/.bashrc</code> or <code>~/.zshrc</code> file: <pre><code>export PATH=/usr/local/cuda-11.2/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n</code></pre></li> <li>Source the file to apply the changes: <pre><code>source ~/.bashrc\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/gpu_computing/cuda/#updating-cuda","title":"Updating CUDA","text":"<p>To update CUDA, follow these steps:</p> <ol> <li> <p>Remove the Existing CUDA Toolkit:     <pre><code>sudo apt-get --purge remove \"*cublas*\" \"cuda*\"\nsudo apt-get autoremove\nsudo apt-get autoclean\n</code></pre></p> </li> <li> <p>Install the New Version:</p> <ul> <li>Follow the installation steps mentioned above with the new version details.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/gpu_computing/cuda/#configuring-cuda-for-effective-performance","title":"Configuring CUDA for Effective Performance","text":"<p>To configure CUDA to run effectively in an HPC environment, consider the following:</p> <ol> <li> <p>Ensure Proper GPU Drivers:</p> <ul> <li>Make sure you have the latest NVIDIA drivers installed. You can check the driver version with: <pre><code>nvidia-smi\n</code></pre></li> </ul> </li> <li> <p>Optimize Kernel Launch Configuration:</p> <ul> <li>Choose the appropriate number of threads per block and blocks per grid based on your GPU's architecture and the problem size.</li> </ul> </li> <li> <p>Use CUDA Streams for Concurrency:</p> <ul> <li>Utilize CUDA streams to overlap computation and data transfer, improving overall performance.</li> </ul> </li> <li> <p>Profile and Optimize:</p> <ul> <li>Use tools like <code>nvprof</code> and <code>Nsight Systems</code> to profile your CUDA applications and identify bottlenecks.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/gpu_computing/cuda/#example-vector-addition","title":"Example: Vector Addition","text":"<p>Here is an example of a simple CUDA program that performs vector addition.</p>"},{"location":"hpc-engineer/gpu_computing/cuda/#cuda-code","title":"CUDA Code","text":"<pre><code>#include &lt;cuda_runtime.h&gt;\n#include &lt;iostream&gt;\n\n__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements) {\n    int i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i &lt; numElements) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main(void) {\n    // Error code to check return values for CUDA calls\n    cudaError_t err = cudaSuccess;\n\n    // Print the vector length to be used, and compute its size\n    int numElements = 50000;\n    size_t size = numElements * sizeof(float);\n    std::cout &lt;&lt; \"[Vector addition of \" &lt;&lt; numElements &lt;&lt; \" elements]\\n\";\n\n    // Allocate the host input vectors A and B\n    float *h_A = (float *)malloc(size);\n    float *h_B = (float *)malloc(size);\n    float *h_C = (float *)malloc(size);\n\n    // Initialize the host input vectors\n    for (int i = 0; i &lt; numElements; ++i) {\n        h_A[i] = rand()/(float)RAND_MAX;\n        h_B[i] = rand()/(float)RAND_MAX;\n    }\n\n    // Allocate the device input vectors A and B\n    float *d_A = NULL;\n    err = cudaMalloc((void **)&amp;d_A, size);\n\n    float *d_B = NULL;\n    err = cudaMalloc((void **)&amp;d_B, size);\n\n    // Allocate the device output vector C\n    float *d_C = NULL;\n    err = cudaMalloc((void **)&amp;d_C, size);\n\n    // Copy the host input vectors A and B in host memory to the device input vectors in device memory\n    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n\n    // Launch the Vector Add CUDA Kernel\n    int threadsPerBlock = 256;\n    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n    vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, numElements);\n\n    // Copy the device result vector in device memory to the host result vector in host memory\n    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n\n    // Verify that the result vector is correct\n    for (int i = 0; i &lt; numElements; ++i) {\n        if (fabs(h_A[i] + h_B[i] - h_C[i]) &gt; 1e-5) {\n            std::cerr &lt;&lt; \"Result verification failed at element \" &lt;&lt; i &lt;&lt; \"!\\n\";\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    std::cout &lt;&lt; \"Test PASSED\\n\";\n\n    // Free device global memory\n    err = cudaFree(d_A);\n    err = cudaFree(d_B);\n    err = cudaFree(d_C);\n\n    // Free host memory\n    free(h_A);\n    free(h_B);\n    free(h_C);\n\n    std::cout &lt;&lt; \"Done\\n\";\n    return 0;\n}\n</code></pre>"},{"location":"hpc-engineer/gpu_computing/cuda/#explanation","title":"Explanation","text":"<ul> <li><code>Kernel Function</code>: The <code>vectorAdd</code> function is executed on the GPU.</li> <li><code>Memory Management</code>: Memory is allocated on both the host and device, and data is copied between them.</li> <li><code>Execution Configuration</code>: The kernel is launched with a specific number of threads and blocks.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/introduction/","title":"Introduction","text":""},{"location":"hpc-engineer/gpu_computing/introduction/#overview","title":"Overview","text":"<p>GPU computing involves using a graphics processing unit (GPU) together with a CPU to accelerate scientific, engineering, and enterprise applications. GPUs are highly efficient at performing parallel computations, making them ideal for tasks such as simulations, deep learning, and data analysis.</p>"},{"location":"hpc-engineer/gpu_computing/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>Parallelism: The ability to perform multiple computations simultaneously.</li> <li>CUDA: A parallel computing platform and API model created by NVIDIA.</li> <li>OpenCL: An open standard for parallel programming of heterogeneous systems.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/introduction/#benefits","title":"Benefits","text":"<ul> <li>Performance: GPUs can significantly accelerate computational tasks.</li> <li>Efficiency: GPUs are optimized for parallel processing, making them more efficient for certain types of computations.</li> <li>Scalability: GPU computing can be scaled across multiple GPUs and nodes.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/introduction/#example-matrix-multiplication","title":"Example: Matrix Multiplication","text":"<p>Here is an example of how GPU computing can be used to perform matrix multiplication.</p>"},{"location":"hpc-engineer/gpu_computing/introduction/#pseudocode","title":"Pseudocode","text":"<pre><code>for each row i in matrix A:\n    for each column j in matrix B:\n        for each element k in row i of A and column j of B:\n            C[i][j] += A[i][k] * B[k][j]\n</code></pre>"},{"location":"hpc-engineer/gpu_computing/introduction/#explanation","title":"Explanation","text":"<ul> <li>Matrix A: The first input matrix.</li> <li>Matrix B: The second input matrix.</li> <li>Matrix C: The result matrix.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>NVIDIA CUDA Documentation</li> <li>OpenCL Documentation</li> </ul>"},{"location":"hpc-engineer/gpu_computing/opencl/","title":"Opencl","text":""},{"location":"hpc-engineer/gpu_computing/opencl/#overview","title":"Overview","text":"<p>OpenCL (Open Computing Language) is an open standard for parallel programming of heterogeneous systems. It allows developers to write programs that execute across different platforms, including CPUs, GPUs, and other processors.</p>"},{"location":"hpc-engineer/gpu_computing/opencl/#key-concepts","title":"Key Concepts","text":"<ul> <li>Platform: Represents a vendor's implementation of OpenCL.</li> <li>Device: A specific compute device (e.g., CPU, GPU) within a platform.</li> <li>Context: The environment within which OpenCL objects are created and managed.</li> <li>Command Queue: A queue that schedules execution of kernels on a device.</li> </ul>"},{"location":"hpc-engineer/gpu_computing/opencl/#example-vector-addition","title":"Example: Vector Addition","text":"<p>Here is an example of a simple OpenCL program that performs vector addition.</p>"},{"location":"hpc-engineer/gpu_computing/opencl/#opencl-code","title":"OpenCL Code","text":"<pre><code>#include &lt;CL/cl.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nconst char *programSource =\n\"__kernel void vectorAdd(__global float *A, __global float *B, __global float *C) {\\n\"\n\"   int idx = get_global_id(0);\\n\"\n\"   C[idx] = A[idx] + B[idx];\\n\"\n\"}\\n\";\n\nint main() {\n    // Initialize data\n    int numElements = 1024;\n    size_t dataSize = sizeof(float) * numElements;\n    float *A = (float *)malloc(dataSize);\n    float *B = (float *)malloc(dataSize);\n    float *C = (float *)malloc(dataSize);\n    for (int i = 0; i &lt; numElements; i++) {\n        A[i] = i;\n        B[i] = i;\n    }\n\n    // Get platform and device information\n    cl_platform_id platformId = NULL;\n    cl_device_id deviceID = NULL;\n    cl_uint retNumDevices;\n    cl_uint retNumPlatforms;\n    cl_int ret = clGetPlatformIDs(1, &amp;platformId, &amp;retNumPlatforms);\n    ret = clGetDeviceIDs(platformId, CL_DEVICE_TYPE_DEFAULT, 1, &amp;deviceID, &amp;retNumDevices);\n\n    // Create an OpenCL context\n    cl_context context = clCreateContext(NULL, 1, &amp;deviceID, NULL, NULL, &amp;ret);\n\n    // Create a command queue\n    cl_command_queue commandQueue = clCreateCommandQueue(context, deviceID, 0, &amp;ret);\n\n    // Create memory buffers on the device for each vector\n    cl_mem aMemObj = clCreateBuffer(context, CL_MEM_READ_ONLY, dataSize, NULL, &amp;ret);\n    cl_mem bMemObj = clCreateBuffer(context, CL_MEM_READ_ONLY, dataSize, NULL, &amp;ret);\n    cl_mem cMemObj = clCreateBuffer(context, CL_MEM_WRITE_ONLY, dataSize, NULL, &amp;ret);\n\n    // Copy the lists A and B to their respective memory buffers\n    ret = clEnqueueWriteBuffer(commandQueue, aMemObj, CL_TRUE, 0, dataSize, A, 0, NULL, NULL);\n    ret = clEnqueueWriteBuffer(commandQueue, bMemObj, CL_TRUE, 0, dataSize, B, 0, NULL, NULL);\n\n    // Create a program from the kernel source\n    cl_program program = clCreateProgramWithSource(context, 1, (const char **)&amp;programSource, NULL, &amp;ret);\n\n    // Build the program\n    ret = clBuildProgram(program, 1, &amp;deviceID, NULL, NULL, NULL);\n\n    // Create the OpenCL kernel\n    cl_kernel kernel = clCreateKernel(program, \"vectorAdd\", &amp;ret);\n\n    // Set the arguments of the kernel\n    ret = clSetKernelArg(kernel, 0, sizeof(cl_mem), (void *)&amp;aMemObj);\n    ret = clSetKernelArg(kernel, 1, sizeof(cl_mem), (void *)&amp;bMemObj);\n    ret = clSetKernelArg(kernel, 2, sizeof(cl_mem), (void *)&amp;cMemObj);\n\n    // Execute the OpenCL kernel on the list\n    size_t globalItemSize = numElements;\n    size_t localItemSize = 64;\n    ret = clEnqueueNDRangeKernel(commandQueue, kernel, 1, NULL, &amp;globalItemSize, &amp;localItemSize, 0, NULL, NULL);\n\n    // Read the memory buffer C on the device to the local variable C\n    ret = clEnqueueReadBuffer(commandQueue, cMemObj, CL_TRUE, 0, dataSize, C, 0, NULL, NULL);\n\n    // Display the result to the screen\n    for (int i = 0; i &lt; numElements; i++) {\n        printf(\"%f + %f = %f\\n\", A[i], B[i], C[i]);\n    }\n\n    // Clean up\n    ret = clFlush(commandQueue);\n    ret = clFinish(commandQueue);\n    ret = clReleaseKernel(kernel);\n    ret = clReleaseProgram(program);\n    ret = clReleaseMemObject(aMemObj);\n    ret = clReleaseMemObject(bMemObj);\n    ret = clReleaseMemObject(cMemObj);\n    ret = clReleaseCommandQueue(commandQueue);\n    ret = clReleaseContext(context);\n    free(A);\n    free(B);\n    free(C);\n\n    return 0;\n}\n</code></pre>"},{"location":"hpc-engineer/gpu_computing/opencl/#explanation","title":"Explanation","text":"<ul> <li><code>Kernel Function</code>: The <code>vectorAdd</code> function is executed on the GPU.</li> <li><code>Memory Management</code>: Memory is allocated on both the host and device, and data is copied between them.</li> <li><code>Execution Configuration</code>: The kernel is launched with a specific number of threads and blocks.</li> </ul>"},{"location":"hpc-engineer/grafana/","title":"Grafana","text":""},{"location":"hpc-engineer/grafana/#overview","title":"Overview","text":"<p>This section covers Grafana, an open-source platform for monitoring and observability.</p>"},{"location":"hpc-engineer/grafana/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>Dashboards</li> <li>Data Sources</li> </ul>"},{"location":"hpc-engineer/grafana/#docker-setup","title":"Docker Setup","text":"<p>To test Grafana setups, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/grafana/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/grafana/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t grafana .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm grafana\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/grafana/dashboards/","title":"Grafana Dashboards","text":""},{"location":"hpc-engineer/grafana/dashboards/#overview","title":"Overview","text":"<p>Grafana dashboards are customizable panels that display data from various sources. They provide a visual representation of your metrics, allowing you to monitor and analyze your data in real-time.</p>"},{"location":"hpc-engineer/grafana/dashboards/#key-features","title":"Key Features","text":"<ul> <li>Panels: Individual visualizations within a dashboard, such as graphs, tables, and gauges.</li> <li>Variables: Dynamic values that can be used in queries to create interactive dashboards.</li> <li>Annotations: Notes and events that can be added to graphs to provide context.</li> <li>Templating: Use variables to create reusable and dynamic dashboards.</li> </ul>"},{"location":"hpc-engineer/grafana/dashboards/#example-creating-a-dashboard","title":"Example: Creating a Dashboard","text":"<p>Here is an example of how to create a simple dashboard in Grafana.</p>"},{"location":"hpc-engineer/grafana/dashboards/#steps","title":"Steps","text":"<ol> <li> <p>Add a Data Source:</p> <ul> <li>Go to Configuration &gt; Data Sources.</li> <li>Click \"Add data source\" and select your data source type.</li> <li>Configure the data source settings and click \"Save &amp; Test\".</li> </ul> </li> <li> <p>Create a Dashboard:</p> <ul> <li>Click the \"+\" icon in the sidebar and select \"Dashboard\".</li> <li>Click \"Add new panel\".</li> <li>Select your data source and configure the query.</li> <li>Choose a visualization type (e.g., Graph, Gauge, Table).</li> <li>Click \"Apply\" to save the panel.</li> </ul> </li> <li> <p>Customize the Dashboard:</p> <ul> <li>Add more panels as needed.</li> <li>Use variables to create dynamic queries.</li> <li>Add annotations to provide context to your data.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/grafana/dashboards/#additional-resources","title":"Additional Resources","text":"<ul> <li>Grafana Dashboards Documentation</li> <li>Grafana GitHub Repository</li> </ul>"},{"location":"hpc-engineer/grafana/data_sources/","title":"Grafana Data Sources","text":""},{"location":"hpc-engineer/grafana/data_sources/#overview","title":"Overview","text":"<p>Data sources in Grafana are the databases or services from which Grafana retrieves data. Grafana supports a wide range of data sources, including time-series databases, SQL databases, and cloud services.</p>"},{"location":"hpc-engineer/grafana/data_sources/#key-features","title":"Key Features","text":"<ul> <li>Wide Range of Integrations: Supports popular data sources like Prometheus, InfluxDB, Elasticsearch, MySQL, PostgreSQL, and many more.</li> <li>Custom Queries: Allows you to write custom queries to retrieve specific data.</li> <li>Authentication: Supports various authentication methods to securely connect to data sources.</li> <li>Plugins: Extend Grafana's capabilities by adding new data source plugins.</li> </ul>"},{"location":"hpc-engineer/grafana/data_sources/#example-adding-a-prometheus-data-source","title":"Example: Adding a Prometheus Data Source","text":"<p>Here is an example of how to add a Prometheus data source in Grafana.</p>"},{"location":"hpc-engineer/grafana/data_sources/#steps","title":"Steps","text":"<ol> <li> <p>Go to Configuration:</p> <ul> <li>Click on the gear icon in the sidebar to go to the Configuration page.</li> <li>Select \"Data Sources\".</li> </ul> </li> <li> <p>Add Data Source:</p> <ul> <li>Click \"Add data source\".</li> <li>Select \"Prometheus\" from the list of available data sources.</li> </ul> </li> <li> <p>Configure Data Source:</p> <ul> <li>Enter the URL of your Prometheus server (e.g., <code>http://localhost:9090</code>).</li> <li>Configure any additional settings as needed.</li> <li>Click \"Save &amp; Test\" to verify the connection.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/grafana/data_sources/#additional-resources","title":"Additional Resources","text":"<ul> <li>Grafana Data Sources Documentation</li> <li>Grafana GitHub Repository</li> </ul>"},{"location":"hpc-engineer/grafana/introduction/","title":"Introduction to Grafana","text":""},{"location":"hpc-engineer/grafana/introduction/#overview","title":"Overview","text":"<p>Grafana is an open-source platform for monitoring and observability. It allows you to query, visualize, alert on, and understand your metrics no matter where they are stored. Grafana provides a powerful and flexible dashboarding capability that can be used to create and share dynamic dashboards.</p>"},{"location":"hpc-engineer/grafana/introduction/#key-features","title":"Key Features","text":"<ul> <li>Data Source Integration: Supports a wide range of data sources including Prometheus, Graphite, InfluxDB, Elasticsearch, and many more.</li> <li>Custom Dashboards: Create custom dashboards with a variety of visualization options.</li> <li>Alerting: Set up alerts to notify you when your metrics meet certain conditions.</li> <li>Plugins: Extend Grafana's functionality with plugins for data sources, panels, and apps.</li> </ul>"},{"location":"hpc-engineer/grafana/introduction/#example-creating-a-dashboard","title":"Example: Creating a Dashboard","text":"<p>Here is an example of how to create a simple dashboard in Grafana.</p>"},{"location":"hpc-engineer/grafana/introduction/#steps","title":"Steps","text":"<ol> <li> <p>Add a Data Source:</p> <ul> <li>Go to Configuration &gt; Data Sources.</li> <li>Click \"Add data source\" and select your data source type.</li> <li>Configure the data source settings and click \"Save &amp; Test\".</li> </ul> </li> <li> <p>Create a Dashboard:</p> <ul> <li>Click the \"+\" icon in the sidebar and select \"Dashboard\".</li> <li>Click \"Add new panel\".</li> <li>Select your data source and configure the query.</li> <li>Choose a visualization type (e.g., Graph, Gauge, Table).</li> <li>Click \"Apply\" to save the panel.</li> </ul> </li> <li> <p>Set Up Alerts:</p> <ul> <li>Open the panel you want to add an alert to.</li> <li>Click the \"Alert\" tab.</li> <li>Click \"Create Alert\" and configure the alert conditions.</li> <li>Set up notification channels and click \"Save\".</li> </ul> </li> </ol>"},{"location":"hpc-engineer/grafana/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>Grafana Documentation</li> <li>Grafana GitHub Repository</li> </ul>"},{"location":"hpc-engineer/job_scheduling/","title":"Index","text":""},{"location":"hpc-engineer/job_scheduling/#overview","title":"Overview","text":"<p>This section covers job scheduling algorithms and tools.</p>"},{"location":"hpc-engineer/job_scheduling/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>Batch Scheduling</li> <li>Real-Time Scheduling</li> <li>Slurm</li> </ul>"},{"location":"hpc-engineer/job_scheduling/#docker-setup","title":"Docker Setup","text":"<p>To test job scheduling tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/job_scheduling/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/job_scheduling/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t job_scheduling .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm job_scheduling\n</code></pre></p> </li> <li> <p>Use Docker Compose to set up the environment:     <pre><code>docker-compose up -d\n</code></pre></p> </li> <li> <p>Access the Slurm controller:     <pre><code>docker exec -it slurm-controller /bin/bash\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/job_scheduling/#additional-resources","title":"Additional Resources","text":"<ul> <li>Slurm Documentation</li> </ul>"},{"location":"hpc-engineer/job_scheduling/batch_scheduling/","title":"Batch scheduling","text":""},{"location":"hpc-engineer/job_scheduling/batch_scheduling/#overview","title":"Overview","text":"<p>Batch scheduling is a method of job scheduling where jobs are collected into batches and executed sequentially. This approach is commonly used in environments where jobs can be processed without immediate user interaction, such as in batch processing systems and high-performance computing clusters.</p>"},{"location":"hpc-engineer/job_scheduling/batch_scheduling/#key-features","title":"Key Features","text":"<ul> <li>Job Collection: Jobs are collected into batches before execution.</li> <li>Sequential Execution: Jobs in a batch are executed one after another.</li> <li>Resource Optimization: Resources are allocated efficiently to maximize throughput.</li> </ul>"},{"location":"hpc-engineer/job_scheduling/batch_scheduling/#example-batch-scheduler","title":"Example: Batch Scheduler","text":"<p>Here is an example of a simple batch scheduler using a queue.</p>"},{"location":"hpc-engineer/job_scheduling/batch_scheduling/#pseudocode","title":"Pseudocode","text":"<pre><code>queue = []\n\nfunction add_job(job):\n    queue.append(job)\n\nfunction run_jobs():\n    while queue is not empty:\n        job = queue.pop(0)\n        execute(job)\n</code></pre>"},{"location":"hpc-engineer/job_scheduling/batch_scheduling/#additional-resources","title":"Additional Resources","text":"<ul> <li>Batch Processing</li> </ul>"},{"location":"hpc-engineer/job_scheduling/introduction/","title":"Introduction","text":""},{"location":"hpc-engineer/job_scheduling/introduction/#overview","title":"Overview","text":"<p>Job scheduling is the process of allocating system resources to various tasks in a way that optimizes performance and efficiency. It is a critical component in operating systems, high-performance computing, and cloud environments.</p>"},{"location":"hpc-engineer/job_scheduling/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>Batch Scheduling: Jobs are collected into batches and executed sequentially.</li> <li>Real-Time Scheduling: Jobs are scheduled to meet specific timing constraints.</li> <li>Priority Scheduling: Jobs are assigned priorities, and higher-priority jobs are executed first.</li> <li>Fair Scheduling: Ensures that all jobs get a fair share of resources.</li> </ul>"},{"location":"hpc-engineer/job_scheduling/introduction/#example-simple-batch-scheduler","title":"Example: Simple Batch Scheduler","text":"<p>Here is an example of a simple batch scheduler using a queue.</p>"},{"location":"hpc-engineer/job_scheduling/introduction/#pseudocode","title":"Pseudocode","text":"<pre><code>queue = []\n\nfunction add_job(job):\n    queue.append(job)\n\nfunction run_jobs():\n    while queue is not empty:\n        job = queue.pop(0)\n        execute(job)\n</code></pre>"},{"location":"hpc-engineer/job_scheduling/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>Job Scheduling Algorithms</li> </ul>"},{"location":"hpc-engineer/job_scheduling/real_time_scheduling/","title":"Real-Time Scheduling","text":""},{"location":"hpc-engineer/job_scheduling/real_time_scheduling/#overview","title":"Overview","text":"<p>Real-time scheduling is a method of job scheduling where jobs are scheduled to meet specific timing constraints. This approach is commonly used in systems where timely execution is critical, such as in embedded systems, robotics, and multimedia applications.</p>"},{"location":"hpc-engineer/job_scheduling/real_time_scheduling/#key-features","title":"Key Features","text":"<ul> <li>Timing Constraints: Jobs have specific deadlines or periods within which they must be executed.</li> <li>Deterministic Behavior: The system's behavior is predictable and consistent.</li> <li>Priority Levels: Jobs are assigned priorities based on their timing requirements.</li> </ul>"},{"location":"hpc-engineer/job_scheduling/real_time_scheduling/#example-real-time-scheduler","title":"Example: Real-Time Scheduler","text":"<p>Here is an example of a simple real-time scheduler using priority queues.</p>"},{"location":"hpc-engineer/job_scheduling/real_time_scheduling/#pseudocode","title":"Pseudocode","text":"<pre><code>priority_queue = []\n\nfunction add_job(job, priority):\n    priority_queue.push(job, priority)\n\nfunction run_jobs():\n    while priority_queue is not empty:\n        job = priority_queue.pop()\n        execute(job)\n</code></pre>"},{"location":"hpc-engineer/job_scheduling/slurm/","title":"Slurm","text":""},{"location":"hpc-engineer/job_scheduling/slurm/#overview","title":"Overview","text":"<p>Slurm is an open-source workload manager designed for high-performance computing (HPC) environments. It is used to allocate resources, schedule jobs, and manage job queues.</p>"},{"location":"hpc-engineer/job_scheduling/slurm/#key-features","title":"Key Features","text":"<ul> <li>Resource Allocation: Efficiently allocates resources to jobs.</li> <li>Job Scheduling: Schedules jobs based on various policies and priorities.</li> <li>Queue Management: Manages job queues and ensures fair resource distribution.</li> </ul>"},{"location":"hpc-engineer/job_scheduling/slurm/#installation-and-configuration","title":"Installation and Configuration","text":""},{"location":"hpc-engineer/job_scheduling/slurm/#installing-slurm","title":"Installing Slurm","text":"<p>To install Slurm on an HPC environment, follow these steps:</p> <ol> <li> <p>Install Slurm:</p> <ul> <li>For Ubuntu, you can use the following commands: <pre><code>sudo apt-get update\nsudo apt-get install -y slurm-wlm\n</code></pre></li> </ul> </li> <li> <p>Configure Slurm:</p> <ul> <li> <p>Edit the Slurm configuration file <code>/etc/slurm-llnl/slurm.conf</code>: <pre><code>sudo nano /etc/slurm-llnl/slurm.conf\n</code></pre></p> </li> <li> <p>Example configuration: <pre><code>ControlMachine=slurm-controller\nMpiDefault=none\nProctrackType=proctrack/linuxproc\nReturnToService=2\nSlurmdPort=6818\nSlurmdSpoolDir=/var/spool/slurmd\nSlurmUser=slurm\nStateSaveLocation=/var/spool/slurmctld\nSwitchType=switch/none\nTaskPlugin=task/affinity\n\n# SCHEDULING\nSchedulerType=sched/backfill\nSelectType=select/cons_res\nSelectTypeParameters=CR_Core\n\n# LOGGING AND ACCOUNTING\nAccountingStorageType=accounting_storage/slurmdbd\nAccountingStorageHost=slurmdbd\nJobAcctGatherType=jobacct_gather/linux\nJobAcctGatherFrequency=30\n\n# COMPUTE NODES\nNodeName=slurm-node[0-9] CPUs=4 State=UNKNOWN\nPartitionName=debug Nodes=slurm-node[0-9] Default=YES MaxTime=INFINITE State=UP\n</code></pre></p> </li> </ul> </li> <li> <p>Start Slurm Services:     <pre><code>sudo systemctl start slurmctld\nsudo systemctl start slurmd\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/job_scheduling/slurm/#submitting-a-job-with-slurm","title":"Submitting a Job with Slurm","text":"<p>Here is an example of how to submit a job using Slurm.</p>"},{"location":"hpc-engineer/job_scheduling/slurm/#command","title":"Command","text":"<pre><code>sbatch my_job_script.sh\n</code></pre>"},{"location":"hpc-engineer/job_scheduling/slurm/#example-job-script","title":"Example Job Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=test_job\n#SBATCH --output=result.out\n#SBATCH --error=result.err\n#SBATCH --time=01:00:00\n#SBATCH --qos=normal\n#SBATCH --partition=debug\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n\nsrun hostname\n</code></pre>"},{"location":"hpc-engineer/job_scheduling/slurm/#configuring-qos-and-limits","title":"Configuring QoS and Limits","text":"<pre><code># QoS settings\nQOSDef=normal\nQOS=normal\nQOS=high\n\n# Limits\nGrpTRES=cpu=1000\nGrpJobs=100\nGrpSubmitJobs=200\n</code></pre>"},{"location":"hpc-engineer/linux_system_administration/","title":"Linux System Administration","text":""},{"location":"hpc-engineer/linux_system_administration/#overview","title":"Overview","text":"<p>This section covers Linux system administration tasks and tools.</p>"},{"location":"hpc-engineer/linux_system_administration/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>User Management</li> <li>System Monitoring</li> </ul>"},{"location":"hpc-engineer/linux_system_administration/#docker-setup","title":"Docker Setup","text":"<p>To test Linux system administration tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/linux_system_administration/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/linux_system_administration/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image:     <pre><code>docker build -t linux_system_administration .\n</code></pre></p> </li> <li> <p>Run the Docker container:     <pre><code>docker run -it --rm linux_system_administration\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/linux_system_administration/introduction/","title":"Introduction to Linux System Administration","text":""},{"location":"hpc-engineer/linux_system_administration/introduction/#overview","title":"Overview","text":"<p>Linux system administration involves managing and maintaining Linux-based systems. This includes tasks such as user management, system monitoring, software installation, and network configuration.</p>"},{"location":"hpc-engineer/linux_system_administration/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>User Management: Creating, modifying, and deleting user accounts.</li> <li>System Monitoring: Monitoring system performance and resource usage.</li> <li>Package Management: Installing, updating, and removing software packages.</li> <li>Network Configuration: Configuring network interfaces and services.</li> </ul>"},{"location":"hpc-engineer/linux_system_administration/introduction/#example-adding-a-user","title":"Example: Adding a User","text":"<p>Here is an example of how to add a new user in a Linux system.</p>"},{"location":"hpc-engineer/linux_system_administration/introduction/#command","title":"Command","text":"<p>```sh sudo adduser newuser</p>"},{"location":"hpc-engineer/linux_system_administration/user_management/","title":"User Management","text":""},{"location":"hpc-engineer/linux_system_administration/user_management/#overview","title":"Overview","text":"<p>User management in Linux involves creating, modifying, and deleting user accounts. It also includes managing user permissions and groups to control access to system resources.</p>"},{"location":"hpc-engineer/linux_system_administration/user_management/#key-commands","title":"Key Commands","text":"<ul> <li>adduser: Adds a new user to the system.</li> <li>usermod: Modifies an existing user account.</li> <li>deluser: Deletes a user account.</li> <li>passwd: Changes a user's password.</li> <li>groups: Displays the groups a user belongs to.</li> </ul>"},{"location":"hpc-engineer/linux_system_administration/user_management/#example-adding-a-user","title":"Example: Adding a User","text":"<p>Here is an example of how to add a new user in a Linux system.</p>"},{"location":"hpc-engineer/linux_system_administration/user_management/#command","title":"Command","text":"<p>```sh sudo adduser newuser</p>"},{"location":"hpc-engineer/parallel_programming/","title":"Index","text":""},{"location":"hpc-engineer/parallel_programming/#docker-setup","title":"Docker Setup","text":"<p>To test these tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/parallel_programming/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker image: <pre><code>docker build -t parallel_programming .\n</code></pre></p> </li> <li> <p>Run the Docker container: <pre><code>docker run -it --rm parallel_programming\n</code></pre></p> </li> </ol>"},{"location":"hpc-engineer/parallel_programming/mpi/","title":"MPI (Message Passing Interface)","text":""},{"location":"hpc-engineer/parallel_programming/mpi/#description","title":"Description","text":"<p>MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computing architectures. It allows multiple processes to communicate with one another by sending and receiving messages.</p>"},{"location":"hpc-engineer/parallel_programming/mpi/#key-concepts","title":"Key Concepts","text":"<ul> <li>Point-to-Point Communication: Direct communication between two processes.</li> <li>Collective Communication: Communication involving a group of processes.</li> <li>Synchronization: Mechanisms to coordinate the execution of processes.</li> </ul>"},{"location":"hpc-engineer/parallel_programming/mpi/#example-code","title":"Example Code","text":""},{"location":"hpc-engineer/parallel_programming/mpi/#c-example","title":"C Example","text":"<p>This example demonstrates a simple MPI program where each process prints its rank.</p> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;stdio.h&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(NULL, NULL);\n\n    int world_size;\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);\n\n    int world_rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);\n\n    printf(\"Hello world from rank %d out of %d processors\\n\", world_rank, world_size);\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre>"},{"location":"hpc-engineer/parallel_programming/openmp/","title":"Parallel Programming Fundamentals","text":""},{"location":"hpc-engineer/parallel_programming/openmp/#openmp","title":"OpenMP","text":""},{"location":"hpc-engineer/parallel_programming/openmp/#description","title":"Description","text":"<p>OpenMP (Open Multi-Processing) is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behavior.</p> <p>OpenMP is designed for parallel programming on shared memory architectures. It allows developers to write parallel code by adding simple compiler directives to their existing code. These directives tell the compiler how to parallelize the code.</p>"},{"location":"hpc-engineer/parallel_programming/openmp/#key-concepts","title":"Key Concepts","text":"<ul> <li>Parallel Regions: Blocks of code that are executed by multiple threads in parallel.</li> <li>Work Sharing: Distributes the execution of code across multiple threads.</li> <li>Synchronization: Mechanisms to control the access to shared resources.</li> </ul>"},{"location":"hpc-engineer/parallel_programming/openmp/#example-code","title":"Example Code","text":""},{"location":"hpc-engineer/parallel_programming/openmp/#c-example","title":"C Example","text":"<p>This example demonstrates a simple parallel region where multiple threads print a message.</p> <pre><code>#include &lt;omp.h&gt;\n#include &lt;stdio.h&gt;\n\nint main() {\n    #pragma omp parallel\n    {\n        int thread_id = omp_get_thread_num();\n        printf(\"Hello from thread %d\\n\", thread_id);\n    }\n    return 0;\n}\n</code></pre>"},{"location":"hpc-engineer/parallel_programming/openmp/#explanation","title":"Explanation","text":"<ul> <li><code>#pragma omp parallel</code>: This directive tells the compiler to execute the following block of code in parallel.</li> <li><code>omp_get_thread_num()</code>: This function returns the thread number of the current thread. How to Compile and Run To compile and run the OpenMP program, you need to use a compiler that supports OpenMP, such as <code>gcc</code>. To compile and run the OpenMP program, you need to use a compiler that supports OpenMP, such as <code>gcc</code>.</li> </ul> <pre><code>gcc -fopenmp -o hello_omp hello_omp.c\n./hello_omp\n</code></pre>"},{"location":"hpc-engineer/parallel_programming/openmp/#advanced-example-parallel-loop","title":"Advanced Example: Parallel Loop","text":"<p>This example demonstrates how to parallelize a loop using OpenMP.</p>"},{"location":"hpc-engineer/parallel_programming/openmp/#c-example_1","title":"C Example","text":"<pre><code>#include &lt;omp.h&gt;\n#include &lt;stdio.h&gt;\n\nint main() {\n    int n = 10;\n    int a[n];\n\n    #pragma omp parallel for\n    for (int i = 0; i &lt; n; i++) {\n        a[i] = i * i;\n        printf(\"Thread %d: a[%d] = %d\\n\", omp_get_thread_num(), i, a[i]);\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"hpc-engineer/parallel_programming/openmp/#explanation_1","title":"Explanation","text":"<p>Explanation - #pragma omp parallel for: This directive tells the compiler to parallelize the following for loop. - Each iteration of the loop is executed by a different thread.</p>"},{"location":"hpc-engineer/parallel_programming/openmp/#how-to-compile-and-run","title":"How to Compile and Run","text":"<pre><code>gcc -fopenmp -o parallel_loop parallel_loop.c\n./parallel_loop\n</code></pre>"},{"location":"hpc-engineer/parallel_programming/openmp/#additional-resources","title":"Additional Resources","text":"<ul> <li>OpenMP Official Website</li> <li>OpenMP API Specification</li> </ul>"},{"location":"hpc-engineer/performance_analysis/","title":"Index","text":""},{"location":"hpc-engineer/performance_analysis/#overview","title":"Overview","text":"<p>This section covers performance analysis techniques and tools.</p>"},{"location":"hpc-engineer/performance_analysis/#contents","title":"Contents","text":"<ul> <li>Introduction</li> <li>Profiling</li> <li>Benchmarking</li> </ul>"},{"location":"hpc-engineer/performance_analysis/#docker-setup","title":"Docker Setup","text":"<p>To test performance analysis tools, you can use the following Docker setup.</p>"},{"location":"hpc-engineer/performance_analysis/#dockerfile","title":"Dockerfile","text":"<p>Refer to the Dockerfile.</p>"},{"location":"hpc-engineer/performance_analysis/#how-to-build-and-run","title":"How to Build and Run","text":"<ol> <li> <p>Build the Docker Image:</p> <ul> <li>Open a terminal and navigate to the directory containing the Dockerfile.</li> <li>Run the following command to build the Docker image: <pre><code>docker build -t performance_analysis .\n</code></pre></li> </ul> </li> <li> <p>Run the Docker Container:</p> <ul> <li>After building the image, run the following command to start the Docker container: <pre><code>docker run -it --rm performance_analysis\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/#additional-resources","title":"Additional Resources","text":"<ul> <li>Gprof Documentation</li> <li>Valgrind Documentation</li> </ul>"},{"location":"hpc-engineer/performance_analysis/benchmarking/","title":"Benchmarking","text":""},{"location":"hpc-engineer/performance_analysis/benchmarking/#overview","title":"Overview","text":"<p>Benchmarking is the practice of running a set of standard tests to evaluate the performance of a system or component. It helps in comparing the performance of different systems and identifying areas for improvement.</p>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#key-concepts","title":"Key Concepts","text":"<ul> <li>Throughput: The amount of work done in a given period.</li> <li>Latency: The time taken to complete a single task.</li> <li>Scalability: The ability of a system to handle increased load.</li> </ul>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#tools-for-benchmarking","title":"Tools for Benchmarking","text":"<ul> <li>Phoronix Test Suite: An open-source benchmarking platform.</li> <li>SPEC CPU: A benchmark suite for evaluating the performance of a computer's processor, memory, and compiler.</li> </ul>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#standard-operating-procedure-sop-for-benchmarking","title":"Standard Operating Procedure (SOP) for Benchmarking","text":""},{"location":"hpc-engineer/performance_analysis/benchmarking/#using-phoronix-test-suite","title":"Using Phoronix Test Suite","text":""},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-1-install-phoronix-test-suite","title":"Step 1: Install Phoronix Test Suite","text":"<ol> <li> <p>Update the Package List:</p> <ul> <li>Open a terminal and run the following command to update the package list: <pre><code>sudo apt-get update\n</code></pre></li> </ul> </li> <li> <p>Install Phoronix Test Suite:</p> <ul> <li>Install the Phoronix Test Suite by running the following command: <pre><code>sudo apt-get install -y phoronix-test-suite\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-2-run-a-benchmark","title":"Step 2: Run a Benchmark","text":"<ol> <li> <p>List Available Tests:</p> <ul> <li>To see a list of available tests, run: <pre><code>phoronix-test-suite list-available-tests\n</code></pre></li> </ul> </li> <li> <p>Execute a Benchmark:</p> <ul> <li>Run the desired benchmark using the following command: <pre><code>phoronix-test-suite benchmark &lt;test-name&gt;\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-3-review-the-results","title":"Step 3: Review the Results","text":"<ol> <li> <p>View Results in Terminal:</p> <ul> <li>The results will be displayed in the terminal after the benchmark completes.</li> </ul> </li> <li> <p>Access Results via Web Interface:</p> <ul> <li>You can also access the results through the Phoronix Test Suite web interface by opening a web browser and navigating to the provided URL.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#using-spec-cpu","title":"Using SPEC CPU","text":""},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-1-install-spec-cpu","title":"Step 1: Install SPEC CPU","text":"<ol> <li> <p>Download SPEC CPU:</p> <ul> <li>Visit the SPEC website and download the SPEC CPU benchmark suite.</li> </ul> </li> <li> <p>Follow Installation Instructions:</p> <ul> <li>Follow the installation instructions provided by SPEC to install the benchmark suite on your system.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-2-configure-spec-cpu","title":"Step 2: Configure SPEC CPU","text":"<ol> <li>Create a Configuration File:<ul> <li>Create a configuration file for your system. Refer to the SPEC documentation for details on how to create this file.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-3-run-a-benchmark","title":"Step 3: Run a Benchmark","text":"<ol> <li>Execute a Benchmark:<ul> <li>Run the desired benchmark using the following command: <pre><code>runspec --config=&lt;config-file&gt; --action=run &lt;benchmark-name&gt;\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#step-4-review-the-results","title":"Step 4: Review the Results","text":"<ol> <li> <p>View Results in Terminal:</p> <ul> <li>The results will be displayed in the terminal after the benchmark completes.</li> </ul> </li> <li> <p>Access Result Files:</p> <ul> <li>The results can also be accessed through the SPEC CPU result files located in the results directory.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/benchmarking/#additional-resources","title":"Additional Resources","text":"<ul> <li>Phoronix Test Suite Documentation</li> <li>SPEC CPU Documentation</li> </ul>"},{"location":"hpc-engineer/performance_analysis/introduction/","title":"Introduction","text":""},{"location":"hpc-engineer/performance_analysis/introduction/#introduction","title":"Introduction","text":"<p>Performance analysis is a critical aspect of high-performance computing (HPC). It involves evaluating the efficiency and effectiveness of a system or application to identify bottlenecks and optimize performance. This section provides an overview of performance analysis techniques and tools commonly used in HPC environments.</p>"},{"location":"hpc-engineer/performance_analysis/introduction/#key-concepts","title":"Key Concepts","text":"<ul> <li>Profiling: The process of measuring the performance of a program, identifying which parts of the program consume the most resources.</li> <li>Benchmarking: The practice of running a set of standard tests to evaluate the performance of a system or component.</li> </ul>"},{"location":"hpc-engineer/performance_analysis/introduction/#tools-for-performance-analysis","title":"Tools for Performance Analysis","text":"<ul> <li>Gprof: A profiling program that collects and displays runtime performance data.</li> <li>Valgrind: An instrumentation framework for building dynamic analysis tools, including a profiler.</li> </ul>"},{"location":"hpc-engineer/performance_analysis/introduction/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>To set up the environment for performance analysis, follow these steps:</p> <ol> <li> <p>Install Docker:</p> <ul> <li>Ensure Docker is installed on your system. You can download and install Docker from here.</li> </ul> </li> <li> <p>Build the Docker Image:</p> <ul> <li>Navigate to the directory containing the Dockerfile.</li> <li>Run the following command to build the Docker image: <pre><code>docker build -t performance_analysis .\n</code></pre></li> </ul> </li> <li> <p>Run the Docker Container:</p> <ul> <li>Start the Docker container using the following command: <pre><code>docker run -it --rm performance_analysis\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/introduction/#using-gprof","title":"Using Gprof","text":"<p>Gprof is a profiling tool that helps identify performance bottlenecks in your code.</p>"},{"location":"hpc-engineer/performance_analysis/introduction/#steps-to-use-gprof","title":"Steps to Use Gprof","text":"<ol> <li> <p>Compile the Program with Profiling Enabled:</p> <ul> <li>Use the <code>-pg</code> flag to compile your program: <pre><code>gcc -pg -o my_program my_program.c\n</code></pre></li> </ul> </li> <li> <p>Run the Program:</p> <ul> <li>Execute the compiled program to generate profiling data: <pre><code>./my_program\n</code></pre></li> </ul> </li> <li> <p>Generate the Profiling Report:</p> <ul> <li>Use Gprof to analyze the profiling data and generate a report: <pre><code>gprof my_program gmon.out &gt; analysis.txt\n</code></pre></li> </ul> </li> <li> <p>Review the Report:</p> <ul> <li>Open the <code>analysis.txt</code> file to review the profiling report and identify performance bottlenecks.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/introduction/#using-valgrind","title":"Using Valgrind","text":"<p>Valgrind is a tool for memory debugging, memory leak detection, and profiling.</p>"},{"location":"hpc-engineer/performance_analysis/introduction/#steps-to-use-valgrind","title":"Steps to Use Valgrind","text":"<ol> <li> <p>Run the Program with Valgrind:</p> <ul> <li>Use Valgrind to execute your program and collect profiling data: <pre><code>valgrind --tool=callgrind ./my_program\n</code></pre></li> </ul> </li> <li> <p>Analyze the Profiling Data:</p> <ul> <li>Use <code>callgrind_annotate</code> to analyze the collected data: <pre><code>callgrind_annotate callgrind.out.&lt;pid&gt;\n</code></pre></li> </ul> </li> <li> <p>Review the Analysis:</p> <ul> <li>Review the output to identify performance bottlenecks and memory issues.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/introduction/#additional-resources","title":"Additional Resources","text":"<ul> <li>Gprof Documentation</li> <li>Valgrind Documentation</li> </ul>"},{"location":"hpc-engineer/performance_analysis/profiling/","title":"Profiling","text":""},{"location":"hpc-engineer/performance_analysis/profiling/#overview","title":"Overview","text":"<p>Profiling is the process of measuring the performance of a program, identifying which parts of the program consume the most resources. This helps in optimizing the code to improve performance.</p>"},{"location":"hpc-engineer/performance_analysis/profiling/#tools-for-profiling","title":"Tools for Profiling","text":"<ul> <li>Gprof: A profiling program that collects and displays runtime performance data.</li> <li>Valgrind: An instrumentation framework for building dynamic analysis tools, including a profiler.</li> </ul>"},{"location":"hpc-engineer/performance_analysis/profiling/#standard-operating-procedure-sop-for-profiling","title":"Standard Operating Procedure (SOP) for Profiling","text":""},{"location":"hpc-engineer/performance_analysis/profiling/#using-gprof","title":"Using Gprof","text":""},{"location":"hpc-engineer/performance_analysis/profiling/#step-1-compile-the-program-with-profiling-enabled","title":"Step 1: Compile the Program with Profiling Enabled","text":"<ol> <li>Compile the Program:<ul> <li>Use the <code>-pg</code> flag to compile your program: <pre><code>gcc -pg -o my_program my_program.c\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#step-2-run-the-program","title":"Step 2: Run the Program","text":"<ol> <li>Execute the Program:<ul> <li>Run the compiled program to generate profiling data: <pre><code>./my_program\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#step-3-generate-the-profiling-report","title":"Step 3: Generate the Profiling Report","text":"<ol> <li>Analyze Profiling Data:<ul> <li>Use Gprof to analyze the profiling data and generate a report: <pre><code>gprof my_program gmon.out &gt; analysis.txt\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#step-4-review-the-report","title":"Step 4: Review the Report","text":"<ol> <li>Open the Report:<ul> <li>Open the <code>analysis.txt</code> file to review the profiling report and identify performance bottlenecks.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#using-valgrind","title":"Using Valgrind","text":""},{"location":"hpc-engineer/performance_analysis/profiling/#step-1-run-the-program-with-valgrind","title":"Step 1: Run the Program with Valgrind","text":"<ol> <li>Execute the Program:<ul> <li>Use Valgrind to execute your program and collect profiling data: <pre><code>valgrind --tool=callgrind ./my_program\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#step-2-analyze-the-profiling-data","title":"Step 2: Analyze the Profiling Data","text":"<ol> <li>Annotate Profiling Data:<ul> <li>Use <code>callgrind_annotate</code> to analyze the collected data: <pre><code>callgrind_annotate callgrind.out.&lt;pid&gt;\n</code></pre></li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#step-3-review-the-analysis","title":"Step 3: Review the Analysis","text":"<ol> <li>Review the Output:<ul> <li>Review the output to identify performance bottlenecks and memory issues.</li> </ul> </li> </ol>"},{"location":"hpc-engineer/performance_analysis/profiling/#additional-resources","title":"Additional Resources","text":"<ul> <li>Gprof Documentation</li> <li>Valgrind Documentation</li> </ul>"},{"location":"irods/fuc/","title":"Frequently Used Commands (FUC!)","text":""},{"location":"irods/fuc/#list-all-users","title":"List All Users","text":"<p>To list all users in iRODS:</p> <ol> <li>Open a terminal and connect to the iRODS server.</li> <li>Use the <code>iadmin lu</code> command to list all users. For example:     <pre><code> iadmin lu\n</code></pre></li> </ol>"},{"location":"irods/fuc/#create-a-user","title":"Create a User","text":"<p>To create a new user in iRODS:</p> <ol> <li>Open a terminal and connect to the iRODS server.</li> <li> <p>Use the <code>iadmin mkuser</code> command followed by the username and user type. For example:     <pre><code> iadmin mkuser john rodsuser\n</code></pre></p> </li> <li> <p>Set password for john <pre><code>iadmin moduser john password SecurePass123\n</code></pre></p> </li> </ol>"},{"location":"irods/fuc/#list-files-with-physical-path","title":"List Files with Physical Path","text":"<p>To list files with their physical path in iRODS: 1. Open a terminal and connect to the iRODS server. 2. Use the <code>ils -L</code> command to list files with their physical path. For example:     <pre><code>ils -L /tempZone/home/john\n</code></pre></p>"},{"location":"irods/fuc/#list-all-resources","title":"List All Resources","text":"<p>To list all resources in iRODS: 1. Open a terminal and connect to the iRODS server. 2. Use the <code>iadmin lr</code> command to list all resources. For example:     <pre><code>iadmin lr\n</code></pre></p>"},{"location":"irods/fuc/#list-all-zones","title":"List All Zones","text":"<p>To list all zones in iRODS, you can use the <code>iadmin</code> command with the <code>lz</code> option. This command lists all the zones configured in your iRODS environment.</p> <ol> <li>To list all zones in iRODS:     <pre><code>iadmin lz\n</code></pre></li> </ol>"},{"location":"irods/installation/installation/","title":"iRODS Installation Guide","text":"<p>This guide provides instructions on how to install iRODS on your system.</p>"},{"location":"irods/installation/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Supported operating system (e.g., CentOS, Ubuntu)</li> <li>Root or sudo access</li> <li>Network connectivity to download packages</li> </ul>"},{"location":"irods/installation/installation/#download","title":"Download","text":"<p>You can see the latest information about packages here: https://packages.irods.org/</p>"},{"location":"irods/installation/installation/#yum-package-manager","title":"YUM package manager","text":"<ol> <li>Install public key and add repository</li> </ol> <pre><code>sudo rpm --import https://packages.irods.org/irods-signing-key.asc\nwget -qO - https://packages.irods.org/renci-irods.yum.repo | sudo tee /etc/yum.repos.d/renci-irods.yum.repo\n</code></pre> <ol> <li>Install from the iRODS repository</li> </ol> <pre><code>sudo yum install irods-server irods-database-plugin-postgres rsyslog postgresql\n</code></pre>"},{"location":"irods/installation/installation/#installation","title":"Installation","text":"<ol> <li> <p>Setup <code>rsyslog</code></p> </li> <li> <p>Create file <code>/etc/rsyslog.d/00-irods.conf</code> <pre><code>$FileCreateMode 0644\n$DirCreateMode 0755\n$Umask 0000\n$template irods_format,\"%msg%\\n\"\n:programname,startswith,\"irodsServer\" /var/log/irods/irods.log;irods_format &amp; stop\n:programname,startswith,\"irodsDelayServer\" /var/log/irods/irods.log;irods_format &amp; stop\n</code></pre></p> </li> <li> <p>Restart rsyslog service.</p> </li> </ol> <pre><code>sudo systemctl restart rsyslog\n</code></pre> <ol> <li> <p>Setup <code>postgres</code></p> </li> <li> <p>Become <code>postgres</code> user and run postgres. <pre><code>sudo su - postgres &amp;&amp; psql\n</code></pre></p> </li> </ol> <pre><code>CREATE USER irods WITH PASSWORD 'testpassword';\nCREATE DATABASE \"ICAT\";\nGRANT ALL PRIVILEGES ON DATABASE \"ICAT\" TO irods;\nALTER DATABASE \"ICAT\" OWNER TO irods;\n</code></pre> <ul> <li> <p>Confirm the permissions by running <code>\\l</code>. <pre><code>&gt;&gt;&gt; \\l\n  Name    |  Owner   | Encoding | Locale Provider | Collate |  Ctype  | ICU Locale | ICU Rules |   Access privileges   \n-----------+----------+----------+-----------------+---------+---------+------------+-----------+-----------------------\n ICAT      | irods    | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           | =Tc/irods            +\n           |          |          |                 |         |         |            |           | irods=CTc/irods\n</code></pre></p> </li> <li> <p>Initiate <code>setup_irods.py</code> <pre><code>sudo python3 /var/lib/irods/scripts/setup_irods.py &lt; \\\n  /var/lib/irods/packaging/localhost_setup_postgres.input\n</code></pre></p> </li> </ul>"},{"location":"irods/installation/installation/#start-irods-service","title":"Start <code>iRODS</code> service","text":"<ol> <li> <p>Starting the service <pre><code>sudo su - irods -c \"~/irodsctl -v start &amp;&amp; ils\"\n</code></pre></p> </li> <li> <p>Set the server name <pre><code>sudo su - irods -c \"iadmin set_delay_server $(hostname)\"\n</code></pre></p> </li> <li> <p>Confirm that server is running <pre><code>ps aux | grep irodsDelayServer\n</code></pre></p> </li> </ol>"},{"location":"irods/tutorials/irule_tutorial/","title":"iRODS Rule Language Tutorial","text":"<p>This tutorial introduces the iRODS Rule Language and how to use <code>irule</code> to execute custom rules.</p>"},{"location":"irods/tutorials/irule_tutorial/#introduction-to-irods-rules","title":"Introduction to iRODS Rules","text":"<p>iRODS rules automate tasks and workflows within the iRODS environment.</p>"},{"location":"irods/tutorials/irule_tutorial/#writing-a-basic-rule","title":"Writing a Basic Rule","text":"<p>Create a file named <code>hello_world.r</code> with the following content: <pre><code>...\n</code></pre></p>"},{"location":"technical-stuff/dragen/","title":"DRAGEN HRD Pipeline settings","text":"<p>See page: https://support-docs.illumina.com/SW/DRAGEN_TSO500_v2.1/Content/SW/Apps/SampleSheetReqs_fDRAG_mTSO500v2.htm</p> <p>This page states how HRD enriched samples should be noted in a samplesheet:</p> Sample Parameter Required Details Sample_Feature No Only required for HRD enriched samples. For DNA samples that have undergone HRD enrichment, enter HRD in this column of the sample sheet. If the sample has not undergone HRD enrichment, leave the field empty."}]}